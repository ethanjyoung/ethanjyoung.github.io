---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

## Nonlinear feature learning in shallow neural networks
Advised by Guido Mont√∫far
  * Neural networks (NNs) are widely used, but the reasons behind their success are still active areas of research. The line of research we are interested in explores how the early phase of gradient descent leads to feature learning. We study low-rank behavior in the gradients of the training loss for various parametrizations (see [here](https://arxiv.org/abs/2011.14522)) of two-layer neural networks in the proportional scaling regime. I have found [these](https://arxiv.org/abs/2205.01445) [papers](https://arxiv.org/abs/2510.01303) to be particularly helpful.

## Kernel methods for continuous-time reinforcement learning
Advised by Yuhua Zhu
  * Consider the continuous-time reinforcement learning (CTRL) problem where the system dynamics are governed by some (unknown) SDE. This recently proposed [framework](https://arxiv.org/abs/2506.05208) integrates discrete-time information into a continuous-time PDE. We know experimentally that solving the LQR problem with this framework using physics-informed NNs does not yield satisfying results. Consequently, we are interested in exploring the use of kernel methods instead.
